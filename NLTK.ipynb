{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Here is some not very interesting text...>\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import Text\n",
    "from nltk.book import *\n",
    "\n",
    "tokens = word_tokenize('Here is some not very interesting text')\n",
    "text = Text(tokens)\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.833333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text6)/len(set(text6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common:  [(':', 1197), ('.', 816), ('!', 801), (',', 731), (\"'\", 421), ('[', 319), (']', 312), ('the', 299), ('I', 255), ('ARTHUR', 225)]\n",
      "Num of \"Grail\":  34\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fdist = FreqDist(text6)\n",
    "print('Most common: ',fdist.most_common(10))\n",
    "print('Num of \"Grail\": ',fdist[\"Grail\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "bigrams = bigrams(text6)\n",
    "bigramsDist = FreqDist(bigrams)\n",
    "bigramsDist[('Sir', 'Robin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "fourgrams = ngrams(text6, 4)\n",
    "fourgramsDist = FreqDist(fourgrams)\n",
    "fourgramsDist[('father', 'smelt', 'of', 'elderberries')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('coconut', 'and', 'you', \"'\")\n",
      "('coconut', \"'\", 's', 'tropical')\n",
      "('coconut', '?', 'ARTHUR', ':')\n",
      "('coconut', '.', 'ARTHUR', ':')\n",
      "('coconut', 'back', 'anyway', '...')\n",
      "('coconut', 'on', 'a', 'line')\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "from nltk import ngrams\n",
    "fourgrams = ngrams(text6, 4)\n",
    "for fourgram in fourgrams: \n",
    "    if fourgram[0] == 'coconut': \n",
    "        print(fourgram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicographical Analysis with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Strange', 'JJ'),\n",
       " ('women', 'NNS'),\n",
       " ('lying', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('ponds', 'NNS'),\n",
       " ('distributing', 'VBG'),\n",
       " ('swordsis', 'NN'),\n",
       " ('no', 'DT'),\n",
       " ('basis', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('system', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('government', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize('Strange women lying in ponds distributing swords'\\\n",
    "'is no basis for a system of government.')\n",
    "from nltk import pos_tag\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('dust', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('thick', 'RB'),\n",
       " ('so', 'RB'),\n",
       " ('he', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('dust', 'VB')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize('The dust was thick so he had to dust')\n",
    "pos_tag(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google is one of the best companies in the world.\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "\n",
    "sentences = sent_tokenize('Google is one of the best companies in the world.'\\\n",
    "' I constantly google myself to see what I\\'m up to.')\n",
    "nouns = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "for sentence in sentences: \n",
    "    if 'google' in sentence.lower(): \n",
    "        taggedWords = pos_tag(word_tokenize(sentence)) \n",
    "        for word in taggedWords: \n",
    "            if word[0].lower() == 'google' and word[1] in nouns: \n",
    "                print(sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
